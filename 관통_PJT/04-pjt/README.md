### 📈 04_PJT: 토스 증권 종목 토론 데이터 수집 및 분석
이번 프로젝트는 Selenium을 활용해 특정 주식 종목의 토론방 댓글을 크롤링하고, Django 웹 애플리케이션을 통해 수집된 데이터를 조회, 삭제, 분석하는 서비스입니다. 
사용자는 관심 있는 회사명을 입력하여 실시간 토론 데이터를 확인하고, 
OpenAI API를 통해 댓글의 전반적인 여론을 분석할 수 있습니다.

---
### ✨ 주요 기능
1. 종목 검색 및 데이터 수집 (F01, F02)
사용자가 메인 페이지에서 회사명을 입력하면 Selenium이 토스 증권 웹사이트에 자동으로 접속하여 해당 종목을 검색합니다.

검색 결과 페이지에서 가장 상단의 종목을 선택한 후,
커뮤니티 탭으로 이동하여 실시간 토론 댓글을 수집합니다.
수집된 회사 이름, 종목 코드, 댓글 내용은 SQLite DB에 안전하게 저장됩니다.


2. 수집 데이터 조회 및 삭제 (F03, F04)
데이터베이스에 저장된 댓글 목록을 웹 화면에 출력하여 사용자가 한눈에 볼 수 있도록 제공합니다.
각 댓글 옆에 삭제 버튼을 배치하여 버튼 클릭 시 데이터베이스와 화면에서 해당 댓글이 즉시 삭제되는 기능을 구현했습니다.


---
### 📚 학습 내용
1. Selenium을 활용한 동적 페이지 크롤링
JavaScript로 동적으로 생성되는 웹 페이지의 구조를 이해하고 정적 라이브러리만으로는 수집이 어려운 데이터를 Selenium을 통해 효과적으로 추출하는 방법을 학습했습니다. 

브라우저를 직접 제어하여 검색, 클릭, 페이지 이동 등 사용자의 행동을 자동화하고, 
WebDriverWait을 통해 페이지 로딩에 따른 타이밍 문제를 해결하는 노하우를 익혔습니다.


2. Django와 크롤러 연동
Django의 View 함수 내에서 크롤링 함수를 호출하고 크롤링이 완료된 후 
반환된 데이터를 받아와 데이터베이스 모델에 저장하는 연동 프로세스를 경험했습니다. 
이를 통해 웹 프레임워크가 단순히 웹 페이지만을 보여주는 것을 넘어 
백그라운드에서 강력한 자동화 작업을 수행하는 백엔드 시스템으로 기능할 수 있음을 이해했습니다.


3. Django ORM을 이용한 데이터 관리 (CRUD)
Django의 ORM(객체 관계 매핑)을 사용하여 SQL 쿼리문 없이 파이썬 코드로 데이터베이스를 조작했습니다.

- **Create**: update_or_create()를 사용하여 중복 데이터를 방지하며 정보를 저장했습니다.

- **Read**: 저장된 댓글 데이터를 filter()나 all()을 통해 조회하고 컨텍스트를 통해 템플릿에 전달했습니다.

- **Delete**: 특정 객체를 get()으로 조회한 후 .delete() 메서드를 실행하여 간편하게 데이터를 삭제했습니다.


---
### 💡 느낀점

처음 Django를 접했을 때는 솔직히 너무 어렵고 막막한 마음이 컸습니다. 
MTV 패턴, urls.py와 views.py의 관계 등 생소한 개념들 앞에서 무엇부터 시작해야 할지 몰라 어려움을 겪었습니다.

하지만 이번 프로젝트를 통해 Selenium으로 동적인 웹사이트의 데이터를 직접 수집하고 그 결과를 Django 웹 화면에 뿌려주는 과정을 처음부터 끝까지 경험하며 막연했던 개념들이 하나로 이어지는 느낌을 받았습니다. 
단순히 웹 페이지만을 만드는 것을 넘어, 데이터를 가져와(Crawling) 가공하고(Django Backend) 사용자에게 보여주는(Template) 전체 흐름을 직접 구축하며 큰 성취감을 느꼈습니다.